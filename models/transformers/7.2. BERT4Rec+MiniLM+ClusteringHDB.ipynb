{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1746150030483,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"},"user_tz":-600},"id":"TY9Ue10cj1HT"},"outputs":[],"source":["# ====================================\n","# Notebook 8.3: BERT4Rec + MiniLM + Clustering (DBSCAN \u0026 HDBSCAN)\n","# Description:\n","# This notebook trains a BERT4Rec model on order sequences and re-ranks\n","# using MiniLM embeddings and cluster attention (DBSCAN and HDBSCAN).\n","# Evaluated using nDCG@20 and Recall@20.\n","# ===================================="]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31162,"status":"ok","timestamp":1746150061655,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"},"user_tz":-600},"id":"fvaEJfC3nIo3","outputId":"7d97210e-58bd-4655-b3f6-3c1d5524b054"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'My-BS-Thesis'...\n","remote: Enumerating objects: 153, done.\u001b[K\n","remote: Counting objects: 100% (153/153), done.\u001b[K\n","remote: Compressing objects: 100% (146/146), done.\u001b[K\n","remote: Total 153 (delta 54), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (153/153), 201.81 MiB | 23.99 MiB/s, done.\n","Resolving deltas: 100% (54/54), done.\n"]}],"source":["import os\n","\n","# === Clone GitHub repository ===\n","repo_dir = \"My-BS-Thesis\"\n","\n","if os.path.exists(repo_dir):\n","    print(f\"{repo_dir} already exists. Removing it...\\n\")\n","    !rm -r {repo_dir}\n","\n","!git clone https://github.com/Goshmar/My-BS-Thesis"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":96640,"status":"ok","timestamp":1746150158298,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"},"user_tz":-600},"id":"fFBh0qO9kC09","outputId":"4e44515b-b140-4104-c75b-fc3de9d6a9ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# === Install dependencies ===\n","!pip install -q torch transformers scikit-learn"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1746150158302,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"},"user_tz":-600},"id":"JplLvqiRnOxS"},"outputs":[],"source":["# # === Install dependencies from requirements.txt ===\n","# !pip install -r My-BS-Thesis/requirements.txt -q"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":9339,"status":"ok","timestamp":1746150167642,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"},"user_tz":-600},"id":"__9lyKGWkGEK"},"outputs":[],"source":["import os\n","import zipfile\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics.pairwise import cosine_similarity\n","import pickle"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1746150167650,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"},"user_tz":-600},"id":"wbGUQGOwkH-8"},"outputs":[],"source":["# === Set paths ===\n","processed_data = os.path.join(repo_dir, \"data\", \"processed\")\n","interim_data = os.path.join(repo_dir, \"data\", \"interim\")\n","artifacts_dir = os.path.join(repo_dir, \"artifacts\")\n","\n","train_zip_path = os.path.join(processed_data, \"train_df.zip\")\n","test_zip_path = os.path.join(processed_data, \"test_df.zip\")\n","cluster_zip_path = os.path.join(interim_data, \"labeled_products_by_behavior.zip\")\n","\n","embedding_zip1 = os.path.join(artifacts_dir, \"item_embeddings_minilm_part1.zip\")\n","embedding_zip2 = os.path.join(artifacts_dir, \"item_embeddings_minilm_part2.zip\")"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2035,"status":"ok","timestamp":1746150169689,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"},"user_tz":-600},"id":"BDdlJzWQkNtq"},"outputs":[],"source":["# === Load data ===\n","with zipfile.ZipFile(train_zip_path, \"r\") as zipf:\n","    with zipf.open(\"train_df.csv\") as f:\n","        train_df = pd.read_csv(f)\n","\n","with zipfile.ZipFile(test_zip_path, \"r\") as zipf:\n","    with zipf.open(\"test_df.csv\") as f:\n","        test_df = pd.read_csv(f)\n","\n","with zipfile.ZipFile(cluster_zip_path, \"r\") as zipf:\n","    with zipf.open(\"labeled_products_by_behavior.csv\") as f:\n","        cluster_df = pd.read_csv(f)\n","\n","# === Load MiniLM embeddings ===\n","def load_embeddings(zip_path):\n","    with zipfile.ZipFile(zip_path, \"r\") as zipf:\n","        name = zipf.namelist()[0]\n","        with zipf.open(name) as f:\n","            return pickle.load(f)\n","\n","embeddings_1 = load_embeddings(embedding_zip1)\n","embeddings_2 = load_embeddings(embedding_zip2)\n","item_embeddings = {**embeddings_1, **embeddings_2}\n","\n","cluster_map = dict(zip(cluster_df[\"encoded_id\"], cluster_df[\"dbscan_cluster\"]))"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46759,"status":"ok","timestamp":1746150216455,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"},"user_tz":-600},"id":"9zh6B-D5kVjt","outputId":"07a37e17-20e7-4653-ef86-eeca381fa554"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 412999/412999 [00:46\u003c00:00, 8835.84it/s] \n"]}],"source":["# === Prepare training sequences ===\n","user_sequences = []\n","item_id_map, reverse_item_id_map = {}, {}\n","item_counter = 0\n","\n","for _, row in tqdm(train_df.iterrows(), total=len(train_df)):\n","    try:\n","        items = list(eval(row[\"products\"]).keys())\n","    except:\n","        continue\n","    encoded = []\n","    for item in items:\n","        if item not in item_id_map:\n","            item_id_map[item] = item_counter\n","            reverse_item_id_map[item_counter] = item\n","            item_counter += 1\n","        encoded.append(item_id_map[item])\n","    if len(encoded) \u003e 1:\n","        user_sequences.append(encoded)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":979,"status":"ok","timestamp":1746150217618,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"},"user_tz":-600},"id":"ReMeCp01orR5"},"outputs":[],"source":["# === Create training dataset ===\n","max_len = 10\n","train_sequences, target_items = [], []\n","\n","for seq in user_sequences:\n","    for i in range(1, len(seq)):\n","        train_sequences.append(seq[:i][-max_len:])\n","        target_items.append(seq[i])\n","\n","pad_token = item_counter\n","\n","class BERT4RecDataset(Dataset):\n","    def __init__(self, sequences, targets, pad_token, max_len):\n","        self.sequences = sequences\n","        self.targets = targets\n","        self.pad_token = pad_token\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        seq = self.sequences[idx]\n","        padded = [self.pad_token] * (self.max_len - len(seq)) + seq\n","        return torch.tensor(padded), torch.tensor(self.targets[idx])\n","\n","train_dataset = BERT4RecDataset(train_sequences, target_items, pad_token, max_len)\n","train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5539,"status":"ok","timestamp":1746150223214,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"},"user_tz":-600},"id":"kwrPsnZnkXnv","outputId":"af11927d-5f1b-4f8b-cdf1-409f0e3b5769"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n"]}],"source":["# === BERT4Rec model ===\n","class BERT4Rec(nn.Module):\n","    def __init__(self, vocab_size, embed_dim=128, num_heads=4, num_layers=2, max_len=10):\n","        super().__init__()\n","        self.embed = nn.Embedding(vocab_size + 1, embed_dim)\n","        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads)\n","        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n","        self.output = nn.Linear(embed_dim, vocab_size)\n","\n","    def forward(self, x):\n","        x = self.embed(x).permute(1, 0, 2)\n","        x = self.encoder(x)\n","        return self.output(x[-1])\n","\n","# === Training ===\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = BERT4Rec(vocab_size=len(item_id_map)).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":773122,"status":"ok","timestamp":1746150996336,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"},"user_tz":-600},"id":"PHGW_DT7kY51","outputId":"d6f772a6-d114-4487-f0ab-0f8f55883a90"},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5417/5417 [00:53\u003c00:00, 102.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ğŸ“‰ Epoch 1 Loss: 6.2007\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5417/5417 [00:51\u003c00:00, 104.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ğŸ“‰ Epoch 2 Loss: 5.6647\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5417/5417 [00:51\u003c00:00, 104.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ğŸ“‰ Epoch 3 Loss: 5.5100\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5417/5417 [00:51\u003c00:00, 105.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ğŸ“‰ Epoch 4 Loss: 5.4118\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5417/5417 [00:51\u003c00:00, 106.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ğŸ“‰ Epoch 5 Loss: 5.3374\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5417/5417 [00:51\u003c00:00, 104.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ğŸ“‰ Epoch 6 Loss: 5.2789\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5417/5417 [00:51\u003c00:00, 104.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ğŸ“‰ Epoch 7 Loss: 5.2313\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5417/5417 [00:51\u003c00:00, 105.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ğŸ“‰ Epoch 8 Loss: 5.1907\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5417/5417 [00:51\u003c00:00, 105.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ğŸ“‰ Epoch 9 Loss: 5.1547\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5417/5417 [00:51\u003c00:00, 105.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ğŸ“‰ Epoch 10 Loss: 5.1244\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5417/5417 [00:51\u003c00:00, 105.20it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ğŸ“‰ Epoch 11 Loss: 5.0975\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5417/5417 [00:51\u003c00:00, 106.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ğŸ“‰ Epoch 12 Loss: 5.0735\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5417/5417 [00:51\u003c00:00, 105.83it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ğŸ“‰ Epoch 13 Loss: 5.0531\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5417/5417 [00:51\u003c00:00, 106.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ğŸ“‰ Epoch 14 Loss: 5.0328\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5417/5417 [00:51\u003c00:00, 104.84it/s]"]},{"name":"stdout","output_type":"stream","text":["ğŸ“‰ Epoch 15 Loss: 5.0136\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["for epoch in range(15):\n","    model.train()\n","    total_loss = 0\n","    for input_seq, target in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n","        input_seq, target = input_seq.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        logits = model(input_seq)\n","        loss = criterion(logits, target)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    print(f\"ğŸ“‰ Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}\")"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1746150996352,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"},"user_tz":-600},"id":"uPvIXGSIkaLd"},"outputs":[],"source":["# === Re-ranking with cluster attention and MiniLM ===\n","def recommend_bert(input_items, cluster_map, top_k=30):\n","    model.eval()\n","    seq = input_items[-max_len:]\n","    padded = [pad_token] * (max_len - len(seq)) + seq\n","    input_tensor = torch.tensor(padded).unsqueeze(0).to(device)\n","\n","    with torch.no_grad():\n","        logits = model(input_tensor).squeeze()\n","        scores = logits.cpu().numpy()\n","\n","    candidate_indices = np.argsort(scores)[::-1][:100]\n","    candidate_items = [reverse_item_id_map[i] for i in candidate_indices if i in reverse_item_id_map]\n","\n","    basket_embeds = [item_embeddings.get(reverse_item_id_map[i]) for i in seq if reverse_item_id_map.get(i) in item_embeddings]\n","    if not basket_embeds:\n","        return candidate_items[:top_k]\n","    basket_vector = np.mean(basket_embeds, axis=0).reshape(1, -1)\n","\n","    scored_items = []\n","    cluster_ids = [cluster_map.get(reverse_item_id_map[i]) for i in seq if reverse_item_id_map.get(i) in cluster_map]\n","    top_cluster = pd.Series(cluster_ids).value_counts().idxmax() if cluster_ids else None\n","\n","    for i in candidate_indices:\n","        prod_id = reverse_item_id_map.get(i)\n","        if prod_id not in item_embeddings:\n","            continue\n","        item_vector = item_embeddings[prod_id].reshape(1, -1)\n","        sim = cosine_similarity(basket_vector, item_vector)[0][0]\n","        prod_cluster = cluster_map.get(prod_id, -1)\n","        boost = 1.2 if prod_cluster == top_cluster else 1.0\n","        final_score = sim * boost\n","        scored_items.append((prod_id, final_score))\n","\n","    scored_items.sort(key=lambda x: x[1], reverse=True)\n","    return [item for item, _ in scored_items[:top_k]]"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1746150996390,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"},"user_tz":-600},"id":"h5wMxEW6kcGs"},"outputs":[],"source":["def ndcg_at_k(actual, predicted, k=20):\n","    dcg = sum(1 / np.log2(i + 2) for i, p in enumerate(predicted[:k]) if p in actual)\n","    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(actual), k)))\n","    return dcg / idcg if idcg \u003e 0 else 0.0\n","\n","def recall_at_k(actual, predicted, k=20):\n","    return len(set(predicted[:k]) \u0026 set(actual)) / len(actual) if actual else 0.0\n","\n","def mean_metric(metric_fn, actual_list, pred_list, k):\n","    return np.mean([metric_fn(a, p, k) for a, p in zip(actual_list, pred_list)])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"JSChIvqfkdUM"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","ğŸ” Evaluating BERT4Rec with DBSCAN re-ranking...\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80000/80000 [31:33\u003c00:00, 42.26it/s]\n"]}],"source":["# === Evaluate on test set ===\n","print(\"\\nğŸ” Evaluating BERT4Rec with DBSCAN re-ranking...\")\n","actual_orders, predicted_orders = [], []\n","\n","for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n","    try:\n","        items = list(eval(row[\"products\"]).keys())\n","        if len(items) \u003c 2:\n","            continue\n","        basket = items[:len(items)//2]\n","        actual = items[len(items)//2:]\n","        input_seq = [item_id_map[i] for i in basket if i in item_id_map]\n","        predicted = recommend_bert(input_seq, cluster_map)\n","        actual_orders.append(actual)\n","        predicted_orders.append(predicted)\n","    except:\n","        continue"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bbieLv67keng"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","ğŸ“ˆ BERT4Rec + DBSCAN nDCG@20: 0.0744\n","ğŸ“ˆ BERT4Rec + DBSCAN Recall@20: 0.1643\n"]}],"source":["# === Final metrics ===\n","ndcg_20 = mean_metric(ndcg_at_k, actual_orders, predicted_orders, k=20)\n","recall_20 = mean_metric(recall_at_k, actual_orders, predicted_orders, k=20)\n","\n","print(f\"\\nğŸ“ˆ BERT4Rec + DBSCAN nDCG@20: {ndcg_20:.4f}\")\n","print(f\"ğŸ“ˆ BERT4Rec + DBSCAN Recall@20: {recall_20:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tyRPt-7Lkf8L"},"outputs":[],"source":["# === Evaluate on test set ===\n","print(\"\\nğŸ” Evaluating BERT4Rec + HDBSCAN\")\n","cluster_map = dict(zip(cluster_df[\"encoded_id\"], cluster_df[\"hdbscan_cluster\"]))\n","actual_orders, predicted_orders = [], []\n","\n","for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n","    try:\n","        items = list(eval(row[\"products\"]).keys())\n","        if len(items) \u003c 2:\n","            continue\n","        basket = items[:len(items)//2]\n","        actual = items[len(items)//2:]\n","        input_seq = [item_id_map[i] for i in basket if i in item_id_map]\n","        predicted = recommend_bert(input_seq, cluster_map)\n","        actual_orders.append(actual)\n","        predicted_orders.append(predicted)\n","    except:\n","        continue"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8tc-N9ATpcSA"},"outputs":[],"source":["ndcg_20_hdb = mean_metric(ndcg_at_k, actual_orders, predicted_orders, k=20)\n","recall_20_hdb = mean_metric(recall_at_k, actual_orders, predicted_orders, k=20)\n","\n","print(f\"\\nğŸ“ˆ BERT4Rec + HDBSCAN nDCG@20: {ndcg_20_hdb:.4f}\")\n","print(f\"ğŸ“ˆ BERT4Rec + HDBSCAN Recall@20: {recall_20_hdb:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"971BAKwspvzF"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN2J/xOFZTWR82Em+VWupZ5","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}