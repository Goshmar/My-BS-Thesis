{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOUnBiLtxKtck5Begml1J8t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ====================================\n","# Notebook 8.1: BERT4Rec + Clustering (DBSCAN & HDBSCAN)\n","# Description:\n","# This notebook trains a BERT4Rec model on order sequences and evaluates it\n","# using DBSCAN and HDBSCAN cluster-based attention re-ranking.\n","# Evaluated using nDCG@20 and Recall@20.\n","# ===================================="],"metadata":{"id":"8sNVn-BvSbrY","executionInfo":{"status":"ok","timestamp":1745995761960,"user_tz":-600,"elapsed":56,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# === Clone GitHub repository ===\n","repo_dir = \"My-BS-Thesis\"\n","\n","if os.path.exists(repo_dir):\n","    print(f\"{repo_dir} already exists. Removing it...\\n\")\n","    !rm -r {repo_dir}\n","\n","!git clone https://github.com/Goshmar/My-BS-Thesis"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"17C3nBkGSlBM","executionInfo":{"status":"ok","timestamp":1745995800611,"user_tz":-600,"elapsed":38648,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}},"outputId":"9c02c856-eb7e-42a5-b523-6b6adff66dd6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'My-BS-Thesis'...\n","remote: Enumerating objects: 147, done.\u001b[K\n","remote: Counting objects: 100% (147/147), done.\u001b[K\n","remote: Compressing objects: 100% (140/140), done.\u001b[K\n","remote: Total 147 (delta 50), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (147/147), 201.81 MiB | 22.17 MiB/s, done.\n","Resolving deltas: 100% (50/50), done.\n"]}]},{"cell_type":"code","source":["# === Install dependencies from requirements.txt ===\n","!pip install -r My-BS-Thesis/requirements.txt -q"],"metadata":{"id":"Mr_Gy-m3Sl71","executionInfo":{"status":"ok","timestamp":1745998383546,"user_tz":-600,"elapsed":60793,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8ab631ed-25b1-417e-c5bb-c1d59bfe2976"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.7/557.7 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.2/160.2 kB\u001b[0m \u001b[31m141.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m171.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.5/768.5 MB\u001b[0m \u001b[31m397.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m122.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Xgdx7RyEfmC","executionInfo":{"status":"ok","timestamp":1745995899997,"user_tz":-600,"elapsed":99367,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}},"outputId":"afa48a98-7b4f-47df-8748-2092d5cb0ae7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# === Install dependencies ===\n","!pip install -q torch transformers"]},{"cell_type":"code","source":["import os\n","import json\n","import pickle\n","import zipfile\n","import random\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader"],"metadata":{"id":"Haf6c0GqEur-","executionInfo":{"status":"ok","timestamp":1745995906109,"user_tz":-600,"elapsed":6109,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# === Set paths ===\n","processed_data = os.path.join(repo_dir, \"data\", \"processed\")\n","interim_data = os.path.join(repo_dir, \"data\", \"interim\")\n","\n","train_zip_path = os.path.join(processed_data, \"train_df.zip\")\n","test_zip_path = os.path.join(processed_data, \"test_df.zip\")\n","cluster_zip_path = os.path.join(interim_data, \"labeled_products_by_behavior.zip\")"],"metadata":{"id":"0rFHaoV0Egdt","executionInfo":{"status":"ok","timestamp":1745995906123,"user_tz":-600,"elapsed":4,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# === Load data ===\n","with zipfile.ZipFile(train_zip_path, \"r\") as zipf:\n","    with zipf.open(\"train_df.csv\") as f:\n","        train_df = pd.read_csv(f)\n","\n","with zipfile.ZipFile(test_zip_path, \"r\") as zipf:\n","    with zipf.open(\"test_df.csv\") as f:\n","        test_df = pd.read_csv(f)\n","\n","with zipfile.ZipFile(cluster_zip_path, \"r\") as zipf:\n","    with zipf.open(\"labeled_products_by_behavior.csv\") as f:\n","        cluster_df = pd.read_csv(f)\n","\n","cluster_map = dict(zip(cluster_df[\"encoded_id\"], cluster_df[\"dbscan_cluster\"]))"],"metadata":{"id":"mhvEUDGiU1Du","executionInfo":{"status":"ok","timestamp":1745995908518,"user_tz":-600,"elapsed":2388,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# === Prepare item sequences ===\n","user_sequences = []\n","item_id_map, reverse_item_id_map = {}, {}\n","item_counter = 0\n","\n","for _, row in tqdm(train_df.iterrows(), total=len(train_df)):\n","    try:\n","        items = list(eval(row[\"products\"]).keys())\n","    except:\n","        continue\n","    encoded = []\n","    for item in items:\n","        if item not in item_id_map:\n","            item_id_map[item] = item_counter\n","            reverse_item_id_map[item_counter] = item\n","            item_counter += 1\n","        encoded.append(item_id_map[item])\n","    if len(encoded) > 1:\n","        user_sequences.append(encoded)"],"metadata":{"id":"fL5e4D2hEyW9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745995951698,"user_tz":-600,"elapsed":43187,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}},"outputId":"3c9654db-2af6-42bd-9e31-9e6a06cde8a3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 412999/412999 [00:43<00:00, 9573.33it/s] \n"]}]},{"cell_type":"code","source":["# === Build training dataset ===\n","max_len = 10\n","train_sequences, target_items = [], []\n","\n","for seq in user_sequences:\n","    for i in range(1, len(seq)):\n","        train_sequences.append(seq[:i][-max_len:])\n","        target_items.append(seq[i])\n","\n","pad_token = item_counter\n","\n","class BERT4RecDataset(Dataset):\n","    def __init__(self, sequences, targets, pad_token, max_len):\n","        self.sequences = sequences\n","        self.targets = targets\n","        self.pad_token = pad_token\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        seq = self.sequences[idx]\n","        padded = [self.pad_token] * (self.max_len - len(seq)) + seq\n","        return torch.tensor(padded), torch.tensor(self.targets[idx])\n","\n","train_dataset = BERT4RecDataset(train_sequences, target_items, pad_token, max_len)\n","train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"],"metadata":{"id":"7BOWiJm0E1S-","executionInfo":{"status":"ok","timestamp":1745995952741,"user_tz":-600,"elapsed":1084,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# === Define model ===\n","class BERT4Rec(nn.Module):\n","    def __init__(self, vocab_size, embed_dim=128, num_heads=4, num_layers=2, max_len=10):\n","        super().__init__()\n","        self.embed = nn.Embedding(vocab_size + 1, embed_dim)\n","        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads)\n","        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n","        self.output = nn.Linear(embed_dim, vocab_size)\n","\n","    def forward(self, x):\n","        x = self.embed(x).permute(1, 0, 2)\n","        x = self.encoder(x)\n","        return self.output(x[-1])\n","\n","# === Train model ===\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = BERT4Rec(vocab_size=len(item_id_map)).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"X2ISerL_ZpuI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745995957910,"user_tz":-600,"elapsed":5167,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}},"outputId":"8022ec46-825a-47ca-95c4-7f4ee55be75c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["for epoch in range(15):\n","    model.train()\n","    total_loss = 0\n","    for input_seq, target in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n","        input_seq, target = input_seq.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        logits = model(input_seq)\n","        loss = criterion(logits, target)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    print(f\"📉 Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}\")"],"metadata":{"id":"6uWXUgeIE98t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745996731060,"user_tz":-600,"elapsed":773146,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}},"outputId":"ebdb17d8-3b64-4347-fa17-539a35a1cdf1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|██████████| 5417/5417 [00:55<00:00, 98.00it/s] \n"]},{"output_type":"stream","name":"stdout","text":["📉 Epoch 1 Loss: 6.2224\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2: 100%|██████████| 5417/5417 [00:51<00:00, 104.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["📉 Epoch 2 Loss: 5.6787\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3: 100%|██████████| 5417/5417 [00:51<00:00, 105.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["📉 Epoch 3 Loss: 5.5227\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4: 100%|██████████| 5417/5417 [00:55<00:00, 98.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["📉 Epoch 4 Loss: 5.4227\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5: 100%|██████████| 5417/5417 [00:52<00:00, 104.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["📉 Epoch 5 Loss: 5.3491\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6: 100%|██████████| 5417/5417 [00:50<00:00, 106.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["📉 Epoch 6 Loss: 5.2891\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7: 100%|██████████| 5417/5417 [00:50<00:00, 106.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["📉 Epoch 7 Loss: 5.2410\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8: 100%|██████████| 5417/5417 [00:50<00:00, 107.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["📉 Epoch 8 Loss: 5.1985\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9: 100%|██████████| 5417/5417 [00:50<00:00, 106.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["📉 Epoch 9 Loss: 5.1640\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10: 100%|██████████| 5417/5417 [00:50<00:00, 106.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["📉 Epoch 10 Loss: 5.1342\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11: 100%|██████████| 5417/5417 [00:50<00:00, 107.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["📉 Epoch 11 Loss: 5.1072\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12: 100%|██████████| 5417/5417 [00:50<00:00, 107.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["📉 Epoch 12 Loss: 5.0850\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13: 100%|██████████| 5417/5417 [00:50<00:00, 106.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["📉 Epoch 13 Loss: 5.0612\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14: 100%|██████████| 5417/5417 [00:51<00:00, 106.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["📉 Epoch 14 Loss: 5.0420\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15: 100%|██████████| 5417/5417 [00:50<00:00, 107.20it/s]"]},{"output_type":"stream","name":"stdout","text":["📉 Epoch 15 Loss: 5.0231\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# === Inference with DBSCAN awareness ===\n","def recommend_bert(input_items, cluster_map, top_k=30):\n","    model.eval()\n","    seq = input_items[-max_len:]\n","    padded = [pad_token] * (max_len - len(seq)) + seq\n","    input_tensor = torch.tensor(padded).unsqueeze(0).to(device)\n","\n","    with torch.no_grad():\n","        logits = model(input_tensor).squeeze()\n","        scores = logits.cpu().numpy()\n","\n","    cluster_ids = [cluster_map.get(reverse_item_id_map[i]) for i in seq if reverse_item_id_map.get(i) in cluster_map]\n","    if not cluster_ids:\n","        top_items = np.argsort(scores)[::-1][:top_k]\n","        return [reverse_item_id_map[i] for i in top_items if i in reverse_item_id_map]\n","\n","    top_cluster = pd.Series(cluster_ids).value_counts().idxmax()\n","    ranked = [(i, s * (1.2 if cluster_map.get(reverse_item_id_map.get(i)) == top_cluster else 1.0))\n","              for i, s in enumerate(scores) if i in reverse_item_id_map]\n","\n","    top_items = sorted(ranked, key=lambda x: x[1], reverse=True)[:top_k]\n","    return [reverse_item_id_map[i] for i, _ in top_items]"],"metadata":{"id":"Io8MEkaXFBy7","executionInfo":{"status":"ok","timestamp":1745996872626,"user_tz":-600,"elapsed":4,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def ndcg_at_k(actual, predicted, k=20):\n","    dcg = sum(1 / np.log2(i + 2) for i, p in enumerate(predicted[:k]) if p in actual)\n","    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(actual), k)))\n","    return dcg / idcg if idcg > 0 else 0.0\n","\n","def recall_at_k(actual, predicted, k=20):\n","    return len(set(predicted[:k]) & set(actual)) / len(actual) if actual else 0.0\n","\n","def mean_metric(metric_fn, actual_list, pred_list, k):\n","    return np.mean([metric_fn(a, p, k) for a, p in zip(actual_list, pred_list)])"],"metadata":{"id":"YUbBJLUJJJDd","executionInfo":{"status":"ok","timestamp":1745996873307,"user_tz":-600,"elapsed":4,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# === Evaluate on test set ===\n","print(\"\\n🔍 Evaluating BERT4Rec with DBSCAN re-ranking...\")\n","actual_orders, predicted_orders = [], []\n","\n","for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n","    try:\n","        items = list(eval(row[\"products\"]).keys())\n","        if len(items) < 2:\n","            continue\n","        basket = items[:len(items)//2]\n","        actual = items[len(items)//2:]\n","        input_seq = [item_id_map[i] for i in basket if i in item_id_map]\n","        predicted = recommend_bert(input_seq, cluster_map)\n","        actual_orders.append(actual)\n","        predicted_orders.append(predicted)\n","    except:\n","        continue"],"metadata":{"id":"8U_rDMlVVR5c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745927486377,"user_tz":-600,"elapsed":549154,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}},"outputId":"d5038e95-826a-4566-d98b-10c98119de03"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🔍 Evaluating BERT4Rec with DBSCAN re-ranking...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80000/80000 [09:09<00:00, 145.53it/s]\n"]}]},{"cell_type":"code","source":["# === Final metrics ===\n","ndcg_20 = mean_metric(ndcg_at_k, actual_orders, predicted_orders, k=20)\n","recall_20 = mean_metric(recall_at_k, actual_orders, predicted_orders, k=20)\n","\n","print(f\"\\n📈 BERT4Rec + DBSCAN nDCG@20: {ndcg_20:.4f}\")\n","print(f\"📈 BERT4Rec + DBSCAN Recall@20: {recall_20:.4f}\")"],"metadata":{"id":"4RcCY_RGVT_3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745927486917,"user_tz":-600,"elapsed":530,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}},"outputId":"9462da9f-4888-41c8-d171-34d122b01af5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","📈 BERT4Rec + DBSCAN nDCG@20: 0.2432\n","📈 BERT4Rec + DBSCAN Recall@20: 0.3795\n"]}]},{"cell_type":"code","source":["# === Evaluate on test set ===\n","print(\"\\n🔍 Evaluating BERT4Rec + HDBSCAN\")\n","cluster_map = dict(zip(cluster_df[\"encoded_id\"], cluster_df[\"hdbscan_cluster\"]))\n","actual_orders, predicted_orders = [], []\n","\n","for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n","    try:\n","        items = list(eval(row[\"products\"]).keys())\n","        if len(items) < 2:\n","            continue\n","        basket = items[:len(items)//2]\n","        actual = items[len(items)//2:]\n","        input_seq = [item_id_map[i] for i in basket if i in item_id_map]\n","        predicted = recommend_bert(input_seq, cluster_map)\n","        actual_orders.append(actual)\n","        predicted_orders.append(predicted)\n","    except:\n","        continue"],"metadata":{"id":"8ZIHZMsaaAPt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745997463732,"user_tz":-600,"elapsed":583307,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}},"outputId":"40dcaeb1-5f33-4eff-8fc0-7a7fc72a9f8c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🔍 Evaluating BERT4Rec + HDBSCAN\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80000/80000 [09:43<00:00, 137.18it/s]\n"]}]},{"cell_type":"code","source":["ndcg_20_hdb = mean_metric(ndcg_at_k, actual_orders, predicted_orders, k=20)\n","recall_20_hdb = mean_metric(recall_at_k, actual_orders, predicted_orders, k=20)\n","\n","print(f\"\\n📈 BERT4Rec + HDBSCAN nDCG@20: {ndcg_20_hdb:.4f}\")\n","print(f\"📈 BERT4Rec + HDBSCAN Recall@20: {recall_20_hdb:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L5b0zhAbVGRq","executionInfo":{"status":"ok","timestamp":1745997463976,"user_tz":-600,"elapsed":242,"user":{"displayName":"Georgii Budnik","userId":"14371656724304164452"}},"outputId":"f378159c-28c7-4020-8ddd-301b4e90bb7f"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","📈 BERT4Rec + HDBSCAN nDCG@20: 0.2473\n","📈 BERT4Rec + HDBSCAN Recall@20: 0.3790\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6u_DuJ-OlPF9"},"execution_count":null,"outputs":[]}]}